{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc5c0da-a455-4899-9953-eb763a2e48a4",
   "metadata": {},
   "source": [
    "# Non-Negative Matrix Factorization on Module 3 Movie Ratings Dataset\n",
    "\n",
    "## Part One\n",
    "\n",
    "First I'll load the movie ratings data and use NMF to predict the missing ratings from the test data. Then I'll measure the RMSE and discuss what it means in the context of this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e08d302-94bf-4de1-81d4-5e65385eb9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from collections import namedtuple\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6143c9fa-8a99-4a07-8ea0-509ca078462d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700146 entries, 0 to 700145\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   uID     700146 non-null  int64\n",
      " 1   mID     700146 non-null  int64\n",
      " 2   rating  700146 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 16.0 MB\n",
      "train data info: None\n",
      "    uID   mID  rating\n",
      "0   744  1210       5\n",
      "1  3040  1584       4\n",
      "2  1451  1293       5\n",
      "3  5455  3176       2\n",
      "4  2507  3074       5\n",
      "Count of movies in training data with zero rating: 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6040 entries, 0 to 6039\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   uID         6040 non-null   int64 \n",
      " 1   gender      6040 non-null   object\n",
      " 2   age         6040 non-null   int64 \n",
      " 3   accupation  6040 non-null   int64 \n",
      " 4   zip         6040 non-null   object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 236.1+ KB\n",
      "users info: None\n",
      "   uID gender  age  accupation    zip\n",
      "0    1      F    1          10  48067\n",
      "1    2      M   56          16  70072\n",
      "2    3      M   25          15  55117\n",
      "3    4      M   45           7  02460\n",
      "4    5      M   25          20  55455\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3883 entries, 0 to 3882\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   mID     3883 non-null   int64 \n",
      " 1   title   3883 non-null   object\n",
      " 2   year    3883 non-null   int64 \n",
      " 3   Doc     3883 non-null   int64 \n",
      " 4   Com     3883 non-null   int64 \n",
      " 5   Hor     3883 non-null   int64 \n",
      " 6   Adv     3883 non-null   int64 \n",
      " 7   Wes     3883 non-null   int64 \n",
      " 8   Dra     3883 non-null   int64 \n",
      " 9   Ani     3883 non-null   int64 \n",
      " 10  War     3883 non-null   int64 \n",
      " 11  Chi     3883 non-null   int64 \n",
      " 12  Cri     3883 non-null   int64 \n",
      " 13  Thr     3883 non-null   int64 \n",
      " 14  Sci     3883 non-null   int64 \n",
      " 15  Mys     3883 non-null   int64 \n",
      " 16  Rom     3883 non-null   int64 \n",
      " 17  Fil     3883 non-null   int64 \n",
      " 18  Fan     3883 non-null   int64 \n",
      " 19  Act     3883 non-null   int64 \n",
      " 20  Mus     3883 non-null   int64 \n",
      "dtypes: int64(20), object(1)\n",
      "memory usage: 637.2+ KB\n",
      "movies info: None\n",
      "   mID                        title  year  Doc  Com  Hor  Adv  Wes  Dra  Ani  \\\n",
      "0    1                    Toy Story  1995    0    1    0    0    0    0    1   \n",
      "1    2                      Jumanji  1995    0    0    0    1    0    0    0   \n",
      "2    3             Grumpier Old Men  1995    0    1    0    0    0    0    0   \n",
      "3    4            Waiting to Exhale  1995    0    1    0    0    0    1    0   \n",
      "4    5  Father of the Bride Part II  1995    0    1    0    0    0    0    0   \n",
      "\n",
      "   ...  Chi  Cri  Thr  Sci  Mys  Rom  Fil  Fan  Act  Mus  \n",
      "0  ...    1    0    0    0    0    0    0    0    0    0  \n",
      "1  ...    1    0    0    0    0    0    0    1    0    0  \n",
      "2  ...    0    0    0    0    0    1    0    0    0    0  \n",
      "3  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "4  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read in data and take a quick look\n",
    "MV_users = pd.read_csv('users.csv')\n",
    "MV_movies = pd.read_csv('movies.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "data = Data(MV_users, MV_movies, train, test)\n",
    "\n",
    "print(f'train data info: {data.train.info()}')\n",
    "print(data.train.head(5))\n",
    "print(f'Count of movies in training data with zero rating: {len(data.train[data.train['rating'] == 0])}')\n",
    "\n",
    "print(f'users info: {data.users.info()}')\n",
    "print(data.users.head(5))\n",
    "\n",
    "print(f'movies info: {data.movies.info()}')\n",
    "print(data.movies.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74f4130-066a-46a0-9394-2bf1c16bc489",
   "metadata": {},
   "source": [
    "## Train Basic NMF Unsupervised Methods\n",
    "\n",
    "NMF is specifically intended for datasets with non-negative values, so it seems like a reasonable choice for predicting movie ratings ranging from 1-5. It typically handles sparse matrices well. The results of NMF will also be more easily interpretable based on the constraints of a movie rating problem (compared to methods like SVD which couild predict negative values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02665b55-b54d-41aa-a72e-5f32fd31158f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline NMF Test RMSE: 2.8594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/decomposition/_nmf.py:1759: ConvergenceWarning: Maximum number of iterations 300 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# First map users and movies to correct indices\n",
    "user_map = {u: i for i, u in enumerate(data.train['uID'].unique())}\n",
    "movie_map = {m: j for j, m in enumerate(data.train['mID'].unique())}\n",
    "n_users = len(user_map)\n",
    "n_movies = len(movie_map)\n",
    "\n",
    "# Convert uID and mID into matrix indices\n",
    "train_user_idx = data.train['uID'].map(user_map)\n",
    "train_movie_idx = data.train['mID'].map(movie_map)\n",
    "# Repeat for test data\n",
    "test_user_idx = data.test['uID'].map(user_map)\n",
    "test_movie_idx = data.test['mID'].map(movie_map)\n",
    "\n",
    "# For test data, we want to remove blank instances where user and movie are both null\n",
    "na_mask = test_user_idx.notna() & test_movie_idx.notna()\n",
    "test_clean = data.test[na_mask]\n",
    "test_user_idx = test_user_idx[na_mask].astype(int)\n",
    "test_movie_idx = test_movie_idx[na_mask].astype(int)\n",
    "\n",
    "# Create sparse matrix for user-movie train data\n",
    "M_train = csr_matrix((data.train['rating'], (train_user_idx, train_movie_idx)), shape=(n_users, n_movies))\n",
    "\n",
    "# BASELINE NMF MODEL\n",
    "nmf_base = NMF(n_components=25, random_state=42, max_iter=300)\n",
    "\n",
    "# fit_transform base model on sparse training matrix\n",
    "# W has dim n_users x n_components\n",
    "W_base = nmf_base.fit_transform(M_train)\n",
    "# H has dim n_components x n_movies\n",
    "H_base = nmf_base.components_\n",
    "\n",
    "# Create predictor from train set decomposed matrices\n",
    "y_pred_base = np.dot(W_base, H_base)\n",
    "\n",
    "# Run RMSE on predictions\n",
    "test_preds_base = y_pred_base[test_user_idx, test_movie_idx]\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_base = np.sqrt(mean_squared_error(test_clean['rating'], test_preds_base))\n",
    "print(f'Baseline NMF Test RMSE: {rmse_base:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776ea2ce-aa8c-451e-a710-2e741d2cfd1d",
   "metadata": {},
   "source": [
    "### Baseline Result\n",
    "The baseline RMSE isn't great at 2.86. A prediction of between 1 and 5 being off by almost 3 points leads to some pretty poor performance.\n",
    "\n",
    "Next I'll test a grid of hyperparameters to try and find the combination that produces the lowest RMSE on test data. I'm choosing to tune the following parameters with a grid search:\n",
    "* **n_components** - number of latent features the model can identify (# topics)\n",
    "* **beta_loss** - different types of loss functions to optimize the model\n",
    "* **l1_ratio** - regularization parameter for loss function\n",
    "(Source: NMF https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html)\n",
    "\n",
    "Once I have these results, I'll use my tuned, trained NMF method to make predictions on the test data and calculate the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "591e9cb1-ae22-44df-bab7-202bd77babac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_components         beta_loss      RMSE\n",
      "3            40  kullback-leibler  2.855662\n",
      "0            20         frobenius  2.867565\n",
      "1            20  kullback-leibler  2.879435\n",
      "5            60  kullback-leibler  2.888133\n",
      "2            40         frobenius  2.920254\n",
      "7            80  kullback-leibler  2.929562\n",
      "4            60         frobenius  2.968313\n",
      "6            80         frobenius  2.999120\n"
     ]
    }
   ],
   "source": [
    "# HYPERPARAMETER TUNING\n",
    "\n",
    "n_components_arr = [20, 40, 60, 80]\n",
    "beta_loss_arr = ['frobenius', 'kullback-leibler']\n",
    "\n",
    "tune_results = []\n",
    "\n",
    "for k in n_components_arr:\n",
    "    for b in beta_loss_arr:        \n",
    "        nmf = NMF(\n",
    "            n_components=k,\n",
    "            beta_loss=b,\n",
    "            solver='mu',\n",
    "            random_state=42,\n",
    "            max_iter=300 # just picked a likely value that left the runtime manageable\n",
    "        )\n",
    "            \n",
    "        # Fit on training matrix\n",
    "        W = nmf.fit_transform(M_train)\n",
    "        H = nmf.components_\n",
    "            \n",
    "        # Predict ratings\n",
    "        R_pred = W @ H\n",
    "            \n",
    "        # Evaluate on test set\n",
    "        preds = R_pred[test_user_idx, test_movie_idx]\n",
    "        rmse = np.sqrt(mean_squared_error(test_clean['rating'], preds))\n",
    "    \n",
    "        tune_results.append({\n",
    "                'n_components': k,\n",
    "                'beta_loss': b,\n",
    "                'RMSE': rmse\n",
    "            })\n",
    "tune_results_df = pd.DataFrame(tune_results).sort_values(by='RMSE', ascending=True)\n",
    "print(tune_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa4b4d9-ab9f-4d5d-b2fc-cfd3ae01f9d8",
   "metadata": {},
   "source": [
    "## Results & Discussion\n",
    "\n",
    "The best NMF model for this dataset still only achieves an RMSE of **2.86** on test data (using n_components=40 and a KL beta loss function).\n",
    "\n",
    "In the Module 3 Lab, even the worst baseline recommender model (using the predict_everything_to_3 method) had an RMSE of around 1.3, which is significantly better performance than NMF on this data.\n",
    "\n",
    "The likely reason for this is that NMF tries to make predictions for ratings between ALL users and ALL movies, when the sparse nature of the data only makes it possible for a small subset of user-movie pairs to actually provide data to train off of. NMF works best on dense matrices. In this case, the loss/optimization problem that NMF is trying to solve has limited data to learn from, so the predictions are not very good. It also assumes that there is meaningful latent structure in feature space that can be identified to help categorize the data, which may not be true in all cases.\n",
    "\n",
    "By contrast, even though the predict_everything_to_3 strategy (alongside the other baseline recommender models) is not very complex, it is reliably able to fill in these blanks with reasonable values by using a global mean rating of 3 before continuing to learn about the item-item relationships. This ends up producing a much more robust predictive model.\n",
    "\n",
    "**Ways to fix this**\n",
    "\n",
    "NMF could be improved if data was normalized before training. This could include subtracting out individual user bias before matrix factorization, or subtracting 3 (to account for the same global mean as the predict_everything_to_3 method)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4080c9-d544-4075-ab45-16ac461db350",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25f6009-2640-47e8-9d50-d63734533925",
   "metadata": {},
   "source": [
    "* NMF\n",
    "\n",
    "  https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html\n",
    "\n",
    "* Step-by-Step NMF Example in Python | by Quin Daly | Medium (July 13, 2023)\n",
    "\n",
    "  Quin Daly\n",
    "\n",
    "  https://medium.com/@quindaly/step-by-step-nmf-example-in-python-9974e38dc9f9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca03a6-ad43-4591-b5db-f02b4984e927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
